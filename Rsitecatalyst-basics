#Download RSiteCatalyst or Load it when neccesary
if(!require(RSiteCatalyst)) install.packages("RSiteCatalyst")
library(RSiteCatalyst)

#Authentication & Set report suite
SCAuth("XX", "XXX")
my.rsid <- "whg-intl-prod-v3"

# Available variables
segments.available <- GetSegments(my.rsid)
metrics.available <- GetMetrics(my.rsid)
elements.available <- GetElements(my.rsid)
evars.available <- GetEvars(my.rsid)
props.available <- GetProps(my.rsid)
calculatedmetrics.available <- GetCalculatedMetrics(my.rsid)  # Only shows simple calculated metrics (Formula between two metrics)


# Metrics to export
vegasVisits <- metrics.available$id[metrics.available$name == "Vegas - Visits"]
casinoVisits <- metrics.available$id[metrics.available$name == "Casino - Visits"]
livecasinoVisits <- metrics.available$id[metrics.available$name == "Live Casino - Visits"]

vegasGL <- metrics.available$id[metrics.available$name == "Vegas - Games Launched"]
casinoGL <- metrics.available$id[metrics.available$name == "Casino - Games Launched"]
livecasinoGL <- metrics.available$id[metrics.available$name == "Live Casino - Games Launched"]


#QueueRanked
QueueRanked <- QueueRanked(my.rsid, 
                             date.from = refDate - 30,
                             date.to = refDate - 1, 
                             metrics = myMetrics$id,
                             elements = "evar11",
                             classification = "Lobbies"
                             top = 50000,   # top = c(1,5), #gets top 1 for Lobbies and top 5 for eVar11
                             selected = selectedAccountNumbers,  # overwrites the top
                             segment.id = segments.available$id[segments.available$name == "Tabs = Favourites"],
                             interval.seconds	= 60,
                             max.attempts = 120
                             ) 
                             
#Trended
QueueTrended <- QueueTrended(my.rsid,
                      date.from = "2018-05-10",
                      date.to = Sys.Date()-1, 
                      metrics = c("cm631_5aaa72c3a90b46030caf552c", "cm631_5aaa73c0d88ec634510adf61"),
                      elements = c("eVar55", "evar11", "eVar59"),
                      classification = "Locations",
                      top = 20000,
                      date.granularity = "hour"
) 

AccountsRolling2 <- QueueTrended(my.rsid, 
                                date.from = "2018-05-10",
                                date.to = Sys.Date()-1, 
                                metrics = metrics.available$id[metrics.available$name %in% c("Live Casino - SB Visits")],
                                elements = "evar11",
                                top = 20
) 




###### USEFUL DOCUMENTATION ######

### Inline Segmentation
# Segments based on Line Items, Classification Value or Multiple Segments
# https://github.com/AdobeDocs/analytics-1.4-apis/blob/master/docs/reporting-api/inline_segments.md
# A thread about segments and filtering: https://forums.adobe.com/thread/2509360

### Avoiding the Rsitecatalyst package limitations	
# SubmitJsonQueueReport - https://www.rdocumentation.org/packages/RSiteCatalyst/versions/1.4.15/topics/SubmitJsonQueueReport



### Pulling larger data sets	
# It may be that the amount of data you require is more than can reasonably be gathered through the API.
# In that instance, other strategies used are, in rough order of performance:
 # Export the raw data dump from Adobe Analytics into a database, then use R connectors for that.
 # R is also integrated into Spark, so Hadoop/SparkR integrations are used.
 # Export Data Warehouse exports via secure FTP to a folder, then read the csv files into R.
 # Build robust scripts that retry timeouts from the API and batch and recombine data over a long period.


### Using Spark for larger data set: http://datafeedtoolbox.com/how-to-setup-sparklyr-an-r-interface-for-apache-spark/

### API response time	
# Response times for the API is variable
 # It can take anywhere between 10 seconds and 5 minutes or even timeout
 # The size of the requested report doesntÂ´make much impact (within reason)
 # Its recommended that you make a function to wrap around API calls to retry if an error detercted if used in automatic scripts
 # The first call is the most expensive. subsequent calls are cached ? this is probably not true



### 
#
#

### 
#
#


### 
#
#

### 
#
#
